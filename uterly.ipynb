{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzi0kgi0rLZ6"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional, to save model)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install kagglehub (if not already installed)\n",
        "!pip install kagglehub gradio\n",
        "\n",
        "# Authenticate for Kaggle\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Upload your kaggle.json if you have it\n",
        "try:\n",
        "    uploaded = files.upload()  # Upload your kaggle.json\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/ #{\"username\":\"\",\"key\":\"\"}\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "except:\n",
        "    # Or generate from credentials\n",
        "    os.environ['KAGGLE_USERNAME'] = \"ithree\"\n",
        "    os.environ['KAGGLE_KEY'] = \"329d53d4f60bc3dd2f9de1fec6d5b363\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda, MaxPooling2D, Concatenate\n",
        "import tensorflow.keras.backend as K"
      ],
      "metadata": {
        "id": "_cRyFp-JrN_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HEATMAP !!!!!!\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Lambda, MaxPooling2D, Concatenate\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import matplotlib.cm as cm\n",
        "import json\n",
        "\n",
        "# Parameters\n",
        "INPUT_SHAPE = (224, 224, 4)  # RGB + edge detection channel\n",
        "NUM_CLASSES = 2  # Just PCOS and Normal (from the Kaggle dataset)\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "# Define the conditions we're working with (only PCOS and normal based on available Kaggle data)\n",
        "CONDITIONS = [\"normal\", \"pcos\"]\n",
        "\n",
        "# Module 1: Dataset Acquisition\n",
        "def download_datasets():\n",
        "    \"\"\"Download datasets from Kaggle.\"\"\"\n",
        "    datasets = {}\n",
        "\n",
        "    # Download PCOS dataset\n",
        "    print(\"Downloading PCOS dataset...\")\n",
        "    pcos_path = kagglehub.dataset_download(\"shnotweta/2000-images-of-ultrasound-for-pcos\")\n",
        "    datasets[\"pcos\"] = {\n",
        "        \"type\": \"image\",\n",
        "        \"path\": os.path.join(pcos_path, \"dataset\", \"pcos\")\n",
        "    }\n",
        "\n",
        "    # Add normal samples path\n",
        "    datasets[\"normal\"] = {\n",
        "        \"type\": \"image\",\n",
        "        \"path\": os.path.join(pcos_path, \"dataset\", \"normal\")\n",
        "    }\n",
        "\n",
        "    print(f\"PCOS dataset downloaded to: {pcos_path}\")\n",
        "    return datasets\n",
        "\n",
        "# Module 2: Image Processing\n",
        "def apply_sobel_filter(image):\n",
        "    \"\"\"Apply Sobel filter for edge detection.\"\"\"\n",
        "    # Convert to grayscale if the image is in color\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    # Ensure grayscale image is in uint8 format\n",
        "    gray = np.clip(gray, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Apply Sobel filter in X and Y directions\n",
        "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "    # Compute gradient magnitude\n",
        "    sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "    # Normalize to 8-bit image\n",
        "    sobel_magnitude = cv2.normalize(sobel_magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    return sobel_magnitude\n",
        "\n",
        "def load_images_from_directory(directory, target_size=(224, 224), max_images=None):\n",
        "    \"\"\"Load images from a directory with optional limit.\"\"\"\n",
        "    images = []\n",
        "    file_paths = [os.path.join(directory, filename) for filename in os.listdir(directory)\n",
        "                 if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'))]\n",
        "\n",
        "    if max_images:\n",
        "        file_paths = file_paths[:max_images]\n",
        "\n",
        "    print(f\"Loading {len(file_paths)} images from {directory}\")\n",
        "\n",
        "    for filepath in file_paths:\n",
        "        try:\n",
        "            img = cv2.imread(filepath)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, target_size)\n",
        "                images.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {filepath}: {e}\")\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "def preprocess_images(images):\n",
        "    \"\"\"Apply preprocessing to images: convert to RGB and add edge detection channel.\"\"\"\n",
        "    processed_images = []\n",
        "    for img in images:\n",
        "        high_pass = apply_sobel_filter(img)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_4ch = np.dstack((img_rgb, high_pass))\n",
        "        processed_images.append(img_4ch)\n",
        "    return np.array(processed_images)\n",
        "\n",
        "def preprocess_single_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"Preprocess a single image for prediction.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not load image from {image_path}\")\n",
        "\n",
        "    img = cv2.resize(img, target_size)\n",
        "    high_pass = apply_sobel_filter(img)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_4ch = np.dstack((img_rgb, high_pass))\n",
        "    return np.expand_dims(img_4ch, axis=0)  # Add batch dimension\n",
        "\n",
        "def preprocess_direct_image(img, target_size=(224, 224)):\n",
        "    \"\"\"Preprocess an image directly from memory.\"\"\"\n",
        "    if img is None:\n",
        "        raise ValueError(\"No image provided\")\n",
        "\n",
        "    img = cv2.resize(img, target_size)\n",
        "    high_pass = apply_sobel_filter(img)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) if len(img.shape) == 3 else np.stack([img]*3, axis=-1)\n",
        "    img_4ch = np.dstack((img_rgb, high_pass))\n",
        "    return np.expand_dims(img_4ch, axis=0)  # Add batch dimension\n",
        "\n",
        "# Module 3: Data Preparation\n",
        "def prepare_data(datasets):\n",
        "    \"\"\"Prepare data for model training.\"\"\"\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Process each condition\n",
        "    for condition, dataset_info in datasets.items():\n",
        "        if os.path.exists(dataset_info[\"path\"]):\n",
        "            print(f\"Processing {condition} images...\")\n",
        "            images = load_images_from_directory(dataset_info[\"path\"])\n",
        "            if len(images) > 0:\n",
        "                processed_images = preprocess_images(images)\n",
        "                all_images.append(processed_images)\n",
        "                all_labels.append(np.full(len(processed_images), condition))\n",
        "            else:\n",
        "                print(f\"No images found for {condition}\")\n",
        "        else:\n",
        "            print(f\"Path not found: {dataset_info['path']}\")\n",
        "\n",
        "    # Combine data from different conditions\n",
        "    X_images = np.concatenate(all_images) if all_images else np.array([])\n",
        "    y_text = np.concatenate(all_labels) if all_labels else np.array([])\n",
        "\n",
        "    # Convert text labels to indices\n",
        "    label_to_index = {condition: idx for idx, condition in enumerate(CONDITIONS)}\n",
        "    y = np.array([label_to_index[label] for label in y_text])\n",
        "    y_categorical = to_categorical(y, num_classes=len(CONDITIONS))\n",
        "\n",
        "    print(f\"Loaded {len(X_images)} images across {len(label_to_index)} classes\")\n",
        "    return X_images, y_categorical, label_to_index\n",
        "\n",
        "# Module 4: Model Building\n",
        "def build_model(input_shape, num_classes):\n",
        "    \"\"\"Build the CNN model with EfficientNetB3 backbone.\"\"\"\n",
        "    # Image input\n",
        "    image_input = Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Extract RGB and edge channels\n",
        "    rgb_channels = Lambda(lambda x: x[:, :, :, :3])(image_input)\n",
        "    edge_channel = Lambda(lambda x: x[:, :, :, 3:4])(image_input)\n",
        "\n",
        "    # Use EfficientNet with RGB channels\n",
        "    base_model = EfficientNetB3(weights='imagenet', include_top=False, input_tensor=rgb_channels)\n",
        "\n",
        "    # Process edge channel separately\n",
        "    edge_x = Conv2D(16, (3, 3), padding='same', activation='relu')(edge_channel)\n",
        "    edge_x = Conv2D(16, (3, 3), padding='same', activation='relu')(edge_x)\n",
        "    edge_x = MaxPooling2D(pool_size=(2, 2))(edge_x)\n",
        "\n",
        "    # Get features from base model\n",
        "    x = base_model.output\n",
        "\n",
        "    # Resize edge features to match base model output\n",
        "    target_shape = K.int_shape(x)[1:3]\n",
        "    edge_x = Conv2D(16, (3, 3), padding='same', activation='relu')(edge_x)\n",
        "    edge_x = GlobalAveragePooling2D()(edge_x)\n",
        "    edge_features = Dense(64, activation='relu')(edge_x)\n",
        "\n",
        "    # Main feature extraction from RGB path\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    rgb_features = Dense(512, activation='relu')(x)\n",
        "\n",
        "    # Combine RGB and edge features\n",
        "    combined = Concatenate()([rgb_features, edge_features])\n",
        "\n",
        "    # Classification layers\n",
        "    x = Dropout(0.5)(combined)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs=image_input, outputs=outputs)\n",
        "\n",
        "    # Freeze early layers for transfer learning\n",
        "    for layer in base_model.layers[:-20]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Module 5: Training and Evaluation\n",
        "def train_model(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Train the model with early stopping and learning rate reduction.\"\"\"\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
        "        ModelCheckpoint('best_pcos_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "    ]\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, label_to_index):\n",
        "    \"\"\"Evaluate the model and display metrics.\"\"\"\n",
        "    # Evaluate on test set\n",
        "    print(\"Evaluating model...\")\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Classification report\n",
        "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
        "    target_names = [index_to_label[i] for i in range(len(CONDITIONS))]\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=target_names, yticklabels=target_names)\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # ROC curves\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(len(CONDITIONS)):\n",
        "        fpr, tpr, _ = roc_curve(y_test[:, i], y_pred_prob[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{target_names[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(\"roc_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "    return test_accuracy\n",
        "\n",
        "# Module 6: Prediction Functions\n",
        "def predict_image(model, image_path, label_to_index):\n",
        "    \"\"\"Make a prediction for a single image.\"\"\"\n",
        "    # Preprocess the image\n",
        "    processed_image = preprocess_single_image(image_path)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(processed_image)[0]\n",
        "\n",
        "    # Convert indices to labels\n",
        "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
        "\n",
        "    # Create result dictionary\n",
        "    results = {index_to_label[i]: float(prediction[i]) for i in range(len(prediction))}\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class = index_to_label[np.argmax(prediction)]\n",
        "    confidence = float(np.max(prediction))\n",
        "\n",
        "    return results, predicted_class, confidence\n",
        "\n",
        "# NEW MODULE: Grad-CAM for Heatmap Generation\n",
        "def make_gradcam_heatmap(model, img_array, pred_index=None):\n",
        "    \"\"\"\n",
        "    Generate a Grad-CAM heatmap for the given image and model.\n",
        "\n",
        "    Args:\n",
        "        model: The model to use for prediction\n",
        "        img_array: The preprocessed image as a numpy array\n",
        "        pred_index: The index of the class to visualize (None means the predicted class)\n",
        "\n",
        "    Returns:\n",
        "        The heatmap as a numpy array\n",
        "    \"\"\"\n",
        "    # Create a model that maps the input image to the activations\n",
        "    # of the last conv layer and the output predictions\n",
        "    last_conv_layer = None\n",
        "\n",
        "    # Find the last convolutional layer\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            last_conv_layer = layer\n",
        "            break\n",
        "\n",
        "    if last_conv_layer is None:\n",
        "        # If we can't find a conv layer, try to use the last layer of the EfficientNet backbone\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.models.Model):  # EfficientNet is a Model\n",
        "                base_model = layer\n",
        "                # Get the last conv layer from the base model\n",
        "                for l in reversed(base_model.layers):\n",
        "                    if isinstance(l, tf.keras.layers.Conv2D):\n",
        "                        last_conv_layer = l\n",
        "                        break\n",
        "                break\n",
        "\n",
        "    if last_conv_layer is None:\n",
        "        print(\"Could not find a convolutional layer for Grad-CAM\")\n",
        "        return None\n",
        "\n",
        "    # Get the gradients of the predicted class (or specified class) with respect to the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Create a model that outputs both the final prediction and the activations of the last conv layer\n",
        "        grad_model = tf.keras.models.Model(\n",
        "            inputs=[model.inputs],\n",
        "            outputs=[model.get_layer(last_conv_layer.name).output, model.output]\n",
        "        )\n",
        "\n",
        "        # Get the activations of the last conv layer and predictions\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "\n",
        "        # Get the score for the predicted class\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the predicted class with respect to\n",
        "    # the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Vector of mean intensity of gradient over feature map\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel in the feature map with its importance\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize the heatmap\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    heatmap = heatmap.numpy()\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "def generate_heatmap_overlay(image_path, model, label_to_index):\n",
        "    \"\"\"\n",
        "    Generate a heatmap overlay for the given image.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the image file\n",
        "        model: The model to use for prediction\n",
        "        label_to_index: Dictionary mapping label names to indices\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (original image, heatmap overlay, predicted class, confidence)\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not load image from {image_path}\")\n",
        "\n",
        "    # Convert to RGB for display\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img_processed = preprocess_single_image(image_path)\n",
        "\n",
        "    # Make a prediction\n",
        "    preds = model.predict(img_processed)\n",
        "    pred_class_idx = np.argmax(preds[0])\n",
        "    confidence = np.max(preds[0])\n",
        "\n",
        "    # Convert indices to labels\n",
        "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
        "    predicted_class = index_to_label[pred_class_idx]\n",
        "\n",
        "    # Generate the heatmap\n",
        "    heatmap = make_gradcam_heatmap(model, img_processed, pred_class_idx)\n",
        "\n",
        "    if heatmap is None:\n",
        "        return img_rgb, img_rgb, predicted_class, confidence\n",
        "\n",
        "    # Resize the heatmap to match the image size\n",
        "    heatmap = cv2.resize(heatmap, (img_rgb.shape[1], img_rgb.shape[0]))\n",
        "\n",
        "    # Create a colored heatmap\n",
        "    heatmap_colored = cm.jet(heatmap)[:, :, :3]  # Remove alpha channel\n",
        "    heatmap_colored = (heatmap_colored * 255).astype(np.uint8)\n",
        "\n",
        "    # Create an overlay image\n",
        "    overlay = img_rgb.copy()\n",
        "    alpha = 0.5  # Transparency factor\n",
        "\n",
        "    # Overlay the heatmap on the image\n",
        "    cv2.addWeighted(heatmap_colored, alpha, img_rgb, 1 - alpha, 0, overlay)\n",
        "\n",
        "    return img_rgb, overlay, predicted_class, confidence\n",
        "\n",
        "# Module 7: Visualization Functions\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot the training history.\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_history.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Module 8: Gradio Frontend with Heatmap Visualization\n",
        "def create_frontend(model_path, label_to_index):\n",
        "    \"\"\"Create a Gradio frontend for model inference with heatmap visualization.\"\"\"\n",
        "    def predict_fn(image):\n",
        "        # Save the uploaded image temporarily\n",
        "        temp_path = \"temp_upload.jpg\"\n",
        "        cv2.imwrite(temp_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Load model if needed\n",
        "        if isinstance(model_path, str):\n",
        "            model = load_model(model_path)\n",
        "        else:\n",
        "            model = model_path\n",
        "\n",
        "        # Make prediction\n",
        "        results, predicted_class, confidence = predict_image(model, temp_path, label_to_index)\n",
        "\n",
        "        # Generate heatmap\n",
        "        original_img, heatmap_overlay, _, _ = generate_heatmap_overlay(temp_path, model, label_to_index)\n",
        "\n",
        "        # Save heatmap for download\n",
        "        heatmap_path = \"heatmap_explanation.png\"\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(original_img)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(heatmap_overlay)\n",
        "        plt.title(\"Activation Heatmap\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.suptitle(f\"Prediction: {predicted_class} (Confidence: {confidence:.2f})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(heatmap_path)\n",
        "        plt.close()\n",
        "\n",
        "        # Create probability bar chart\n",
        "        fig = plt.figure(figsize=(8, 4))\n",
        "        plt.bar(list(results.keys()), list(results.values()), color=['blue' if v != np.max(list(results.values())) else 'red' for v in results.values()])\n",
        "        plt.ylim(0, 1)\n",
        "        plt.ylabel('Probability')\n",
        "        plt.title(f'Prediction: {predicted_class} (Confidence: {confidence:.2f})')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Create explanation of the heatmap\n",
        "        explanation = f\"\"\"\n",
        "        ## Detected condition: {predicted_class}\n",
        "        Confidence: {confidence:.2%}\n",
        "\n",
        "        ### Explanation:\n",
        "        The heatmap shows which areas of the image influenced the model's prediction.\n",
        "        Warmer colors (red/yellow) indicate areas that strongly contributed to the prediction,\n",
        "        while cooler colors (blue) had less influence.\n",
        "\n",
        "        For PCOS detection, the model typically focuses on:\n",
        "        - Follicle distribution and appearance\n",
        "        - Ovarian size and texture\n",
        "        - Stromal echogenicity (brightness)\n",
        "\n",
        "        ### Download Results:\n",
        "        You can download the heatmap visualization for further analysis.\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate heatmap metadata\n",
        "        heatmap_metadata = {\n",
        "            \"prediction\": predicted_class,\n",
        "            \"confidence\": float(confidence),\n",
        "            \"class_probabilities\": {k: float(v) for k, v in results.items()},\n",
        "            \"timestamp\": pd.Timestamp.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Save metadata\n",
        "        with open(\"heatmap_metadata.json\", \"w\") as f:\n",
        "            json.dump(heatmap_metadata, f, indent=2)\n",
        "\n",
        "        os.remove(temp_path)  # Clean up\n",
        "\n",
        "        return fig, heatmap_overlay, explanation, heatmap_path\n",
        "\n",
        "    # Create Gradio interface\n",
        "    demo = gr.Interface(\n",
        "        fn=predict_fn,\n",
        "        inputs=gr.Image(),\n",
        "        outputs=[\n",
        "            gr.Plot(label=\"Probability Distribution\"),\n",
        "            gr.Image(label=\"Heatmap Visualization\"),\n",
        "            gr.Markdown(label=\"Explanation\"),\n",
        "            gr.File(label=\"Download Heatmap\")\n",
        "        ],\n",
        "        title=\"PCOS Detection with Explainable AI\",\n",
        "        description=\"Upload an ultrasound scan to detect if it shows PCOS or normal condition. The heatmap shows which image areas influenced the model's decision.\",\n",
        "        examples=[\"example1.jpg\", \"example2.jpg\"]  # You can add example images here\n",
        "    )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    \"\"\"Main function to orchestrate the entire workflow.\"\"\"\n",
        "    # 1. Download datasets\n",
        "    print(\"Step 1: Downloading datasets...\")\n",
        "    datasets = download_datasets()\n",
        "\n",
        "    # 2. Prepare data\n",
        "    print(\"Step 2: Preparing data...\")\n",
        "    X, y, label_to_index = prepare_data(datasets)\n",
        "\n",
        "    # 3. Split the data\n",
        "    print(\"Step 3: Splitting data...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "    print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n",
        "\n",
        "    # 4. Build model\n",
        "    print(\"Step 4: Building model...\")\n",
        "    model = build_model(INPUT_SHAPE, NUM_CLASSES)\n",
        "    model.summary()\n",
        "\n",
        "    # 5. Train model\n",
        "    print(\"Step 5: Training model...\")\n",
        "    model, history = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # 6. Visualize training\n",
        "    print(\"Step 6: Visualizing training history...\")\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # 7. Evaluate model\n",
        "    print(\"Step 7: Evaluating model...\")\n",
        "    evaluate_model(model, X_test, y_test, label_to_index)\n",
        "\n",
        "    # 8. Save model\n",
        "    model_path = \"pcos_detection_model.h5\"\n",
        "    model.save(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    # 9. Create and launch frontend\n",
        "    print(\"Step 8: Creating demo frontend...\")\n",
        "    demo = create_frontend(model, label_to_index)\n",
        "    demo.launch()\n",
        "\n",
        "# Entry point\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# Simplified demo for direct use\n",
        "def run_demo(model_path=\"pcos_detection_model.h5\"):\n",
        "    \"\"\"Run just the demo frontend with a pre-trained model.\"\"\"\n",
        "    # Define the conditions we're using\n",
        "    conditions = [\"normal\", \"pcos\"]\n",
        "    label_to_index = {condition: idx for idx, condition in enumerate(conditions)}\n",
        "\n",
        "    # Check if model exists\n",
        "    if os.path.exists(model_path):\n",
        "        # Create and launch frontend\n",
        "        demo = create_frontend(model_path, label_to_index)\n",
        "        demo.launch()\n",
        "    else:\n",
        "        print(f\"Model file {model_path} not found. Please run the main function first to train the model.\")"
      ],
      "metadata": {
        "id": "OZtYkO4WrT-F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}